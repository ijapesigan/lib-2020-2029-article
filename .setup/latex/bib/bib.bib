@Article{Adolf-Loossens-Tuerlinckx-etal-2021,
  author = {Janne K. Adolf and Tim Loossens and Francis Tuerlinckx and Eva Ceulemans},
  date = {2021-12},
  journaltitle = {Psychological Methods},
  title = {Optimal sampling rates for reliable continuous-time first-order autoregressive and vector autoregressive modeling},
  doi = {10.1037/met0000398},
  issn = {1082-989X},
  number = {6},
  pages = {701--718},
  volume = {26},
  abstract = {Autoregressive and vector autoregressive models are a driving force in current psychological research. In affect research they are, for instance, frequently used to formalize affective processes and estimate affective dynamics. Discrete-time model variants are most commonly used, but continuous-time formulations are gaining popularity, because they can handle data from longitudinal studies in which the sampling rate varies within the study period, and yield results that can be compared across data sets from studies with different sampling rates. However, whether and how the sampling rate affects the quality with which such continuous-time models can be estimated, has largely been ignored in the literature. In the present article, we show how the sampling rate affects the estimation reliability (i.e., the standard errors of the parameter estimators, with smaller values indicating higher reliability) of continuous-time autoregressive and vector autoregressive models. Moreover, we determine which sampling rates are optimal in the sense that they lead to standard errors of minimal size (subject to the assumption that the models are correct). Our results are based on the theories of optimal design and maximum likelihood estimation. We illustrate them making use of data from the COGITO Study. We formulate recommendations for study planning, and elaborate on strengths and limitations of our approach.},
  publisher = {American Psychological Association (APA)},
}

@Article{Ash-Gueorguieva-Barnett-etal-2022,
  author = {Garrett I. Ash and Ralitza Gueorguieva and Nancy P. Barnett and Wuyi Wang and David S. Robledo and Kelly S. DeMartini and Brian Pittman and Nancy S. Redeker and Stephanie S. O\textquoterightMalley and Lisa M. Fucito},
  date = {2022-05},
  journaltitle = {Alcoholism: Clinical and Experimental Research},
  title = {Sensitivity, specificity, and tolerability of the {BACTrack Skyn} compared to other alcohol monitoring approaches among young adults in a field‐based setting},
  doi = {10.1111/acer.14804},
  issn = {1530-0277},
  number = {5},
  pages = {783--796},
  volume = {46},
  abstract = {Background: There is a need for novel alcohol biosensors that are accurate, able to detect alcohol concentration close in time to consumption, and feasible and acceptable for many clinical and research applications. We evaluated the field accuracy and tolerability of novel (BACTrack Skyn) and established (Alcohol Monitoring Systems SCRAM CAM) alcohol biosensors. Methods: The sensor and diary data were collected in a larger study of a biofeedback intervention and compared observationally in the present sub-study. Participants (high-risk drinkers, 40\% female; median age 21) wore both Skyn and SCRAM CAM sensors for 1-6 days and were instructed to drink as usual. Data from the first cohort of participants ($N = 27$; 101 person-days) were used to find threshold values of transdermal alcohol that classified each day as meeting or not meeting defined levels of drinking (heavy, above-moderate, any). These values were used to develop scoring metrics that were subsequently tested using the second cohort ($N = 20$; 57 person-days). Data from both biosensors were compared to mobile diary self-report to evaluate sensitivity and specificity in relation to a priori standards established in the literature. Results: Skyn classification rules for Cohort \#1 within 3 months of device shipment showed excellent sensitivity for heavy drinking (94\%) and exceeded expectations for above-moderate and any drinking (78\% and 69\%, respectively), while specificity met expectations (91\%). However, classification worsened when Cohort \#1 devices $\geq 3$ months from shipment were tested (area under curve for receiver operator characteristic 0.87 vs. 0.79) and the derived classification threshold when applied to Cohort \#2 was inadequately specific (70\%). Skyn tolerability metrics were excellent and exceeded the SCRAM CAM ($p \leq 0.001$). Conclusions: Skyn tolerability was favorable and accuracy rules were internally derivable but did not yield useful scoring metrics going forward across device lots and months of usage.},
  publisher = {Wiley},
}

@Article{Bakk-Kuha-2020,
  author = {Zsuzsa Bakk and Jouni Kuha},
  date = {2020-11},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  title = {Relating latent class membership to external variables: An overview},
  doi = {10.1111/bmsp.12227},
  issn = {2044-8317},
  number = {2},
  pages = {340--362},
  volume = {74},
  abstract = {In this article we provide an overview of existing approaches for relating latent class membership to external variables of interest. We extend on the work of Nylund-Gibson et al. (Structural Equation Modeling: A Multidisciplinary Journal, 2019, 26, 967), who summarize models with distal outcomes by providing an overview of most recommended modeling options for models with covariates and larger models with multiple latent variables as well. We exemplify the modeling approaches using data from the General Social Survey for a model with a distal outcome where underlying model assumptions are violated, and a model with multiple latent variables. We discuss software availability and provide example syntax for the real data examples in Latent GOLD.},
  publisher = {Wiley},
}

@Article{Cheung-2021,
  author = {Mike W.-L. Cheung},
  date = {2021-06},
  journaltitle = {Alcohol and Alcoholism},
  title = {Synthesizing indirect effects in mediation models with meta-analytic methods},
  doi = {10.1093/alcalc/agab044},
  number = {1},
  pages = {5--15},
  volume = {57},
  abstract = {Aims
  A mediator is a variable that explains the underlying mechanism between an independent variable and a dependent variable. The indirect effect indicates the effect from the predictor to the outcome variable via the mediator. In contrast, the direct effect represents the predictor's effort on the outcome variable after controlling for the mediator.
  Methods
  A single study rarely provides enough evidence to answer research questions in a particular domain. Replications are generally recommended as the gold standard to conduct scientific research. When a sufficient number of studies have been conducted addressing similar research questions, a meta-analysis can be used to synthesize those studies' findings.
  Results
  The main objective of this paper is to introduce two frameworks to integrating studies using mediation analysis. The first framework involves calculating standardized indirect effects and direct effects and conducting a multivariate meta-analysis on those effect sizes. The second one uses meta-analytic structural equation modeling to synthesize correlation matrices and fit mediation models on the average correlation matrix. We illustrate these procedures on a real dataset using the R statistical platform.
  Conclusion
  This paper closes with some further directions for future studies.},
  publisher = {Oxford University Press ({OUP})},
  keywords = {heterogeneity, gold standard, outcome variable, datasets, mediation analysis},
}

@Article{Cheung-Cheung-Lau-etal-2022,
  author = {Shu Fai Cheung and Sing-Hang Cheung and Esther Yuet Ying Lau and C. Harry Hui and Weng Ngai Vong},
  date = {2022-07},
  journaltitle = {Health Psychology},
  title = {Improving an old way to measure moderation effect in standardized units.},
  doi = {10.1037/hea0001188},
  issn = {0278-6133},
  number = {7},
  pages = {502--505},
  volume = {41},
  abstract = {Moderation effects in multiple regression, tested usually by the inclusion of a product term, are frequently investigated in health psychology. However, several issues in presenting the moderation effects in standardized units and their associated confidence intervals are commonly observed. While an old method had been proposed to standardize variables in moderated regression before fitting a moderated regression model, this method was rarely used due to inconvenience and even when used, the confidence intervals derived were biased. Here, we attempt to solve these two problems by providing a tool to conveniently conduct standardization in moderated regression without the step of standardizing the variables beforehand and to accurately form the nonparametric bootstrapping confidence intervals for this standardized measure of moderation effects. Health psychology researchers are now equipped with a tool that can be used to report and interpret standardized moderation effects correctly.},
  publisher = {American Psychological Association (APA)},
}

@Article{Cheung-Pesigan-2023a,
  author = {Shu Fai Cheung and Ivan Jacob Agaloos Pesigan},
  date = {2023-01},
  journaltitle = {Multivariate Behavioral Research},
  title = {{FINDOUT}: Using either {SPSS} commands or graphical user interface to identify influential cases in structural equation modeling in {AMOS}},
  doi = {10.1080/00273171.2022.2148089},
  number = {5},
  pages = {964--968},
  volume = {58},
  abstract = {The results in a structural equation modeling (SEM) analysis can be influenced by just a few observations, called influential cases. Tools have been developed for users of R to identify them. However, similar tools are not available for AMOS, which is also a popular SEM software package. We introduce the FINDOUT toolset, a group of SPSS extension commands, and an AMOS plugin, to identify influential cases and examine how these cases influence the results. The SPSS commands can be used either as syntax commands or as custom dialogs from pull-down menus, and the AMOS plugin can be run from AMOS pull-down menu. We believe these tools can help researchers to examine the robustness of their findings to influential cases.},
  publisher = {Informa {UK} Limited},
  keywords = {influential cases, outliers, structural equation modeling, AMOS, sensitivity analysis, SPSS},
}

@Article{Cheung-Pesigan-2023b,
  author = {Shu Fai Cheung and Ivan Jacob Agaloos Pesigan},
  date = {2023-05},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {{semlbci}: An {R} package for forming likelihood-based confidence intervals for parameter estimates, correlations, indirect effects, and other derived parameters},
  doi = {10.1080/10705511.2023.2183860},
  number = {6},
  pages = {985--999},
  volume = {30},
  abstract = {There are three common types of confidence interval (CI) in structural equation modeling (SEM): Wald-type CI, bootstrapping CI, and likelihood-based CI (LBCI). LBCI has the following advantages: (1) it has better coverage probabilities and Type I error rate compared to Wald-type CI when the sample size is finite; (2) it correctly tests the null hypothesis of a parameter based on likelihood ratio chi-square difference test; (3) it is less computationally intensive than bootstrapping CI; and (4) it is invariant to transformations. However, LBCI is not available in many popular SEM software packages. We developed an R package, semlbci, for forming LBCI for parameters in models fitted by lavaan, a popular open-source SEM package, such that researchers have more options in forming CIs for parameters in SEM. The package supports both unstandardized and standardized estimates, derived parameters such as indirect effect, multisample models, and the robust LBCI proposed by Falk.},
  publisher = {Informa {UK} Limited},
  keywords = {confidence interval, likelihood-based confidence interval, robust method, structural equation modeling},
  annotation = {r, r-packages, sem, sem-software, sem-likelihood},
}

@Article{Cheung-Pesigan-Vong-2022,
  author = {Shu Fai Cheung and Ivan Jacob Agaloos Pesigan and Weng Ngai Vong},
  date = {2022-03},
  journaltitle = {Behavior Research Methods},
  title = {{DIY} bootstrapping: Getting the nonparametric bootstrap confidence interval in {SPSS} for any statistics or function of statistics (when this bootstrapping is appropriate)},
  doi = {10.3758/s13428-022-01808-5},
  number = {2},
  pages = {474--490},
  volume = {55},
  abstract = {Researchers can generate bootstrap confidence intervals for some statistics in SPSS using the BOOTSTRAP command. However, this command can only be applied to selected procedures, and only to selected statistics in these procedures. We developed an extension command and prepared some sample syntax files based on existing approaches from the Internet to illustrate how researchers can (a) generate a large number of nonparametric bootstrap samples, (b) do desired analysis on all these samples, and (c) form the bootstrap confidence intervals for selected statistics using the OMS commands. We developed these tools to help researchers apply nonparametric bootstrapping to any statistics for which this method is appropriate, including statistics derived from other statistics, such as standardized effect size measures computed from the t test results. We also discussed how researchers can extend the tools for other statistics and scenarios they encounter.},
  publisher = {Springer Science and Business Media {LLC}},
  keywords = {bootstrapping, effect sizes, confidence intervals},
}

@Article{Courtney-Russell-2021,
  author = {Jimikaye B. Courtney and Michael A. Russell},
  date = {2021-08},
  journaltitle = {Psychology of Addictive Behaviors},
  title = {Testing affect regulation models of drinking prior to and after drinking initiation using ecological momentary assessment},
  doi = {10.1037/adb0000763},
  issn = {0893-164X},
  number = {5},
  pages = {597--608},
  volume = {35},
  abstract = {Objective: Affect regulation models of drinking state that affect motivates and reinforces drinking. Few studies have been able to elucidate the timing of these associations in natural settings. We tested positive affect (PA) and negative affect (NA) as predictors of drinking behavior, both prior to and during drinking episodes, and whether drinking predicted changes in affect during episodes. Method: Two hundred twenty two regularly drinking young adults (21–29 years, 84\% undergraduates), completed an ecological momentary assessment (EMA) protocol for five consecutive 24-hr periods stretching across 6 days (Wednesday–Monday). Participants provided PA and NA reports three times daily and every half hour during drinking episodes. Alcohol consumption reports were provided each morning and every half hour during drinking episodes. Results: Multi-level models showed that greater pre-drinking PA predicted higher odds of drinking and greater number of drinks consumed. Pre-drinking NA did not predict same day odds of drinking or drinks consumed. Episode-level results revealed different associations for PA and NA with drinking. Current PA did not predict drinks consumed over the next half hour; however, increased drinking was associated with greater increases in PA over the next half hour. Higher NA predicted fewer drinks consumed in the next half hour and higher odds of the end of a drinking episode; however, increased drinking was not associated with changes in NA. Conclusions: PA increased following drinking during episodes. Our results suggest that a focus on PA prior to episodes and a focus on NA during episodes may interrupt processes leading to heavy drinking, and may therefore aid prevention efforts.},
  publisher = {American Psychological Association (APA)},
}

@Article{DeMartini-Gueorguieva-Taylor-etal-2022,
  author = {Kelly S. DeMartini and Ralitza Gueorguieva and Jane R. Taylor and Suchitra Krishnan-Sarin and Godfrey Pearlson and John H. Krystal and Stephanie S. O'Malley},
  date = {2022-04},
  journaltitle = {Drug and Alcohol Dependence},
  title = {Dynamic structural equation modeling of the relationship between alcohol habit and drinking variability},
  doi = {10.1016/j.drugalcdep.2021.109202},
  issn = {0376-8716},
  pages = {109202},
  volume = {233},
  abstract = {Background: A hyper-engaged habit system may be common in alcohol use disorders (AUDs). Regarding drinking patterns, habit may be expressed as higher levels of drinking autoregression, where previous day drinking is correlated with next day drinking. This study utilized dynamic structural equation models (DSEM) with intensive longitudinal data to understand whether alcohol habit relates to drinking autoregression and variable levels of alcohol consumption. Methods: Participants were adult drinkers ($N = 313$) who completed baseline self-report assessments of past 30-day alcohol consumption and alcohol habit. Alcohol habit was measured by the Self Report Habit Index (SRHI). Thirty-day coding of the Timeline Followback assessed total daily drinking and any daily heavy drinking. Results: The DSEM model for daily drinking found a weak but significant autoregressive data structure. Alcohol habit was related to increased mean drinking but did not strengthen the autoregressive effect of drinks per day. Higher alcohol habit was associated with higher levels of drinks per day person-specific variability. This pattern was replicated with the DSEM model for heavy drinking. Alcohol habit did not impact the autoregressive effect of heavy drinking but was associated with higher levels of heavy drinking. Conclusions: While both drinks per day and heavy drinking showed a significant autoregressive structure, evidence of alcohol habit did not strengthen this effect. Alcohol habit did impact drinking variability; higher alcohol habit is associated with greater levels of drinking variability and higher mean drinking. Strategies to regulate drinking variability, including heavier drinking occasions, could target AUD habit.},
  keywords = {alcohol, alcohol habit, Bayesian modeling, habit learning, heavy drinking},
  publisher = {Elsevier BV},
}

@Article{Didier-King-Polley-etal-2023,
  author = {Nathan A. Didier and Andrea C. King and Eric C. Polley and Daniel J. Fridberg},
  date = {2023-10},
  journaltitle = {Experimental and Clinical Psychopharmacology},
  title = {Signal processing and machine learning with transdermal alcohol concentration to predict natural environment alcohol consumption.},
  doi = {10.1037/pha0000683},
  issn = {1064-1297},
  number = {2},
  pages = {245--254},
  volume = {32},
  abstract = {Wrist-worn alcohol biosensors continuously and discreetly record transdermal alcohol concentration (TAC) and may allow alcohol researchers to monitor alcohol consumption in participants’ natural environments. However, the field lacks established methods for signal processing and detecting alcohol events using these devices. We developed software that streamlines analysis of raw data (TAC, temperature, and motion) from a wrist-worn alcohol biosensor (BACtrack Skyn) through a signal processing and machine learning pipeline: biologically implausible skin surface temperature readings (< 28C) were screened for potential device removal and TAC artifacts were corrected, features that describe TAC (e.g., rise duration) were calculated and used to train models (random forest and logistic regression) that predict self-reported alcohol consumption, and model performances were measured and summarized in autogenerated reports. The software was tested using 60 Skyn data sets recorded during 30 alcohol drinking episodes and 30 nonalcohol drinking episodes. Participants (N = 36; 13 with alcohol use disorder) wore the Skyn during one alcohol drinking episode and one nonalcohol drinking episode in their natural environment. In terms of distinguishing alcohol from nonalcohol drinking, correcting artifacts in the data resulted in 10\% improvement in model accuracy relative to using raw data. Random forest and logistic regression models were both accurate, correctly predicting 97\% (58/60; AUC-ROCs = 0.98, 0.96) of episodes. Area under TAC curve, rise duration of TAC curve, and peak TAC were the most important features for predictive accuracy. With promising model performance, this protocol will enhance the efficiency and reliability of TAC sensors for future alcohol monitoring research.},
  publisher = {American Psychological Association (APA)},
}

@Article{Dora-Piccirillo-Foster-etal-2023,
  author = {Jonas Dora and Marilyn Piccirillo and Katherine T. Foster and Kelly Arbeau and Stephen Armeli and Marc Auriacombe and Bruce Bartholow and Adriene M. Beltz and Shari M. Blumenstock and Krysten Bold and Erin E. Bonar and Abby Braitman and Ryan W. Carpenter and Kasey G. Creswell and Tracy {De Hart} and Robert D. Dvorak and Noah Emery and Matthew Enkema and Catharine E. Fairbairn and Anne M. Fairlie and Stuart G. Ferguson and Teresa Freire and Fallon Goodman and Nisha Gottfredson and Max Halvorson and Maleeha Haroon and Andrea L. Howard and Andrea Hussong and Kristina M. Jackson and Tiffany Jenzer and Dominic P. Kelly and Adam M. Kuczynski and Alexis Kuerbis and Christine M. Lee and Melissa Lewis and Ashley N. Linden-Carmichael and Andrew Littlefield and David M. Lydon-Staley and Jennifer E. Merrill and Robert Miranda and Cynthia Mohr and Jennifer P. Read and Clarissa Richardson and Roisin M. O'Connor and Stephanie S. O'Malley and Lauren Papp and Thomas M. Piasecki and Paul Sacco and Nichole Scaglione and Fuschia Serre and Julia Shadur and Kenneth J. Sher and Yuichi Shoda and Tracy L. Simpson and Michele R. Smith and Angela Stevens and Brittany Stevenson and Howard Tennen and Michael Todd and Hayley {Treloar Padovano} and Timothy Trull and Jack Waddell and Katherine Walukevich-Dienst and Katie Witkiewitz and Tyler Wray and Aidan G. C. Wright and Andrea M. Wycoff and Kevin M. King},
  date = {2023-01},
  journaltitle = {Psychological Bulletin},
  title = {The daily association between affect and alcohol use: A meta-analysis of individual participant data},
  doi = {10.1037/bul0000387},
  issn = {0033-2909},
  number = {1–2},
  pages = {1--24},
  volume = {149},
  abstract = {Influential psychological theories hypothesize that people consume alcohol in response to the experience of both negative and positive emotions. Despite two decades of daily diary and ecological momentary assessment research, it remains unclear whether people consume more alcohol on days they experience higher negative and positive affects in everyday life. In this preregistered meta-analysis, we synthesized the evidence for these daily associations between affect and alcohol use. We included individual participant data from 69 studies (N = 12,394), which used daily and momentary surveys to assess the affect and the number of alcoholic drinks consumed. Results indicate that people are not more likely to drink on days they experience high negative affect but are more likely to drink and drink heavily on days high in positive affect. People self-reporting a motivational tendency to drink-to-cope and drink-to-enhance consumed more alcohol but not on days they experienced higher negative and positive affects. Results were robust across different operationalizations of affect, study designs, study populations, and individual characteristics. These findings challenge the long-held belief that people drink more alcohol following increase in negative affect. Integrating these findings under different theoretical models and limitations of this field of research, we collectively propose an agenda for future research to explore open questions surrounding affect and alcohol use.},
  publisher = {American Psychological Association (APA)},
}

@Article{Fridberg-Wang-Porges-2022,
  author = {Daniel J. Fridberg and Yan Wang and Eric Porges},
  date = {2022-02},
  journaltitle = {Alcoholism: Clinical and Experimental Research},
  title = {Examining features of transdermal alcohol biosensor readings: A promising approach with implications for research and intervention},
  doi = {10.1111/acer.14794},
  issn = {1530-0277},
  number = {4},
  pages = {514--516},
  volume = {46},
  publisher = {Wiley},
}

@Article{Georgeson-AlvarezBartolo-MacKinnon-2023,
  author = {A. R. Georgeson and Diana Alvarez-Bartolo and David P. MacKinnon},
  date = {2023-12},
  journaltitle = {Psychological Methods},
  title = {A sensitivity analysis for temporal bias in cross-sectional mediation},
  doi = {10.1037/met0000628},
  abstract = {For over three decades, methodologists have cautioned against the use of cross-sectional mediation analyses because they yield biased parameter estimates. Yet, cross-sectional mediation models persist in practice and sometimes represent the only analytic option. We propose a sensitivity analysis procedure to encourage a more principled use of cross-sectional mediation analysis, drawing inspiration from Gollob and Reichardt (1987, 1991). The procedure is based on the two-wave longitudinal mediation model and uses phantom variables for the baseline data. After a researcher provides ranges of possible values for cross-lagged, autoregressive, and baseline Y and M correlations among the phantom and observed variables, they can use the sensitivity analysis to identify longitudinal conditions in which conclusions from a cross-sectional model would differ most from a longitudinal model. To support the procedure, we first show that differences in sign and effect size of the b-path occur most often when the cross-sectional effect size of the b-path is small and the cross-lagged and the autoregressive correlations are equal or similar in magnitude. We then apply the procedure to cross-sectional analyses from real studies and compare the sensitivity analysis results to actual results from a longitudinal mediation analysis. While no statistical procedure can replace longitudinal data, these examples demonstrate that the sensitivity analysis can recover the effect that was actually observed in the longitudinal data if provided with the correct input information. Implications of the routine application of sensitivity analysis to temporal bias are discussed. R code for the procedure is provided in the online supplementary materials.},
  publisher = {American Psychological Association (APA)},
  keywords = {mediation, cross-sectional mediation, sensitivity analysis},
  annotation = {mediation},
}

@Article{Gunn-Steingrimsson-Merrill-etal-2021,
  author = {Rachel L. Gunn and Jon A. Steingrimsson and Jennifer E. Merrill and Timothy Souza and Nancy Barnett},
  date = {2021-05},
  journaltitle = {Drug and Alcohol Review},
  title = {Characterising patterns of alcohol use among heavy drinkers: A cluster analysis utilising alcohol biosensor data},
  doi = {10.1111/dar.13306},
  issn = {1465-3362},
  number = {7},
  pages = {1155--1164},
  volume = {40},
  abstract = {Introduction: Previous research has predominately relied on person-level or single characteristics of drinking episodes to characterise patterns of drinking that may confer risk. This research often relies on self-report measures. Advancements in wearable alcohol biosensors provide a multi-faceted objective measure of drinking. The current study aimed to characterise drinking episodes using data derived from a wearable alcohol biosensor. Methods: Participants ($n = 45$) were adult heavy drinkers who wore the Secure Continuous Remote Alcohol Monitoring (SCRAM) bracelet and reported on their drinking behaviours. Cluster analysis was used to evaluate unique combinations of alcohol episode characteristics. Associations between clusters and self-reported person and event-level factors were also examined in univariable and multivariable models. Results: Results suggested three unique clusters: Cluster 1 (most common, slowest rate of rise to and decline from peak), Cluster 2 (highest peak transdermal alcohol concentration and area under the curve) and Cluster 3 (fastest rate of decline from peak). Univariable analyses distinguished Cluster 1 as having fewer self-reported drinks and fewer episodes that occurred on weekends relative to Cluster 2. The effect for number of drinks remained in multivariable analyses. Discussion and Conclusions: This is the first study to characterise drinking patterns at the event-level using objective data. Results suggest that it is possible to distinguish drinking episodes based on several characteristics derived from wearable alcohol biosensors. This examination lays the groundwork for future studies to characterise patterns of drinking and their association with consequences of drinking behaviour.},
  publisher = {Wiley},
}

@Article{Hamaker-Muthen-2020,
  author = {Ellen L. Hamaker and Bengt Muth{\a'e}n},
  date = {2020-06},
  journaltitle = {Psychological Methods},
  title = {The fixed versus random effects debate and how it relates to centering in multilevel modeling},
  doi = {10.1037/met0000239},
  issn = {1082-989X},
  number = {3},
  pages = {365--379},
  volume = {25},
  abstract = {In many disciplines researchers use longitudinal panel data to investigate the potentially causal relationship between 2 variables. However, the conventions and concerns vary widely across disciplines. Here we focus on 2 concerns, that is: (a) the concern about random effects versus fixed effects, which is central in the (micro)econometrics/sociology literature; and (b) the concern about grand mean versus group (or person) mean centering, which is central in the multilevel literature associated with disciplines like psychology and educational sciences. We show that these 2 concerns are actually addressing the same underlying issue. We discuss diverse modeling methods based on either multilevel regression modeling with the data in long format, or structural equation modeling with the data in wide format, and compare these approaches with simulated data. We extend the multilevel model with random slopes and discuss the consequences of this. Subsequently, we provide guidelines on how to choose between the diverse modeling options. We illustrate the use of these guidelines with an empirical example based on intensive longitudinal data, in which we consider both a time-varying and a time-invariant covariate.},
  publisher = {American Psychological Association (APA)},
}

@Article{Hecht-Zitzmann-2020a,
  author = {Martin Hecht and Steffen Zitzmann},
  date = {2020-03},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {A computationally more efficient {Bayesian} approach for estimating continuous-time models},
  doi = {10.1080/10705511.2020.1719107},
  issn = {1532-8007},
  number = {6},
  pages = {829--840},
  volume = {27},
  abstract = {Continuous-time modeling is gaining in popularity as more and more intensive longitudinal data need to be analyzed. Current Bayesian software implementations of continuous-time models suffer from rather high, inadequate run times. Therefore, we apply a model reformulation approach to reduce run time. In a simulation study, we investigate the estimation quality and run time gain. We then illustrate our optimized Bayesian continuous-time model estimation and compare it to established continuous-time modeling software using an empirical example. Parameter estimates and inference statistics were very comparable, while run times were very different. Our approach reduces the run times for Bayesian estimations of continuous-time models from hours to minutes.},
  publisher = {Informa UK Limited},
}

@Article{Hecht-Zitzmann-2020b,
  author = {Martin Hecht and Steffen Zitzmann},
  date = {2020-07},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {Sample size recommendations for continuous-time models: Compensating shorter time series with larger numbers of persons and vice versa},
  doi = {10.1080/10705511.2020.1779069},
  issn = {1532-8007},
  number = {2},
  pages = {229--236},
  volume = {28},
  abstract = {Autoregressive modeling has traditionally been concerned with time-series data from one unit (N = 1). For short time series (T < 50), estimation performance problems are well studied and documented. Fortunately, in psychological and social science research, besides T, another source of information is often available for model estimation, that is, the persons (N > 1). In this work, we illustrate the N/T compensation effect: With an increasing number of persons N at constant T, the model estimation performance increases, and vice versa, with an increasing number of time points T at constant N, the performance increases as well. Based on these observations, we develop sample size recommendations in the form of easily accessible N/T heatmaps for two popular autoregressive continuous-time models.},
  publisher = {Informa UK Limited},
}

@Article{Hecht-Zitzmann-2021,
  author = {Martin Hecht and Steffen Zitzmann},
  date = {2021-05},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {Exploring the unfolding of dynamic effects with continuous-time models: Recommendations concerning statistical power to detect peak cross-lagged effects},
  doi = {10.1080/10705511.2021.1914627},
  issn = {1532-8007},
  number = {6},
  pages = {894--902},
  volume = {28},
  abstract = {Cross-lagged panel models have been commonly applied to investigate the dynamic interplay of variables. In such discrete-time models, the size of the cross-lagged effects depends on the length of the time interval between the measurement occasions. Continuous-time modeling allows to explore this interval dependence of cross-lagged effects and thus to identify the maximal “peak” cross-lagged effects. To detect these peak effects, sufficient statistical power is needed. Based on results from a simulation study, we employed machine learning algorithms to identify a highly accurate prediction model. Results are incorporated into a Shiny App (available at https://psychtools.shinyapps.io/ ContinuousTimePowerCalculation) for easy power calculations. Although limitations apply, our results might be helpful for study planning.},
  publisher = {Informa UK Limited},
}

@Article{Li-Oravecz-Zhou-etal-2022,
  author = {Yanling Li and Zita Oravecz and Shuai Zhou and Yosef Bodovski and Ian J. Barnett and Guangqing Chi and Yuan Zhou and Naomi P. Friedman and Scott I. Vrieze and Sy-Miin Chow},
  date = {2022-01},
  journaltitle = {Psychometrika},
  title = {{Bayesian} forecasting with a regime-switching zero-inflated multilevel poisson regression model: An application to adolescent alcohol use with spatial covariates},
  doi = {10.1007/s11336-021-09831-9},
  number = {2},
  pages = {376--402},
  volume = {87},
  abstract = {In this paper, we present and evaluate a novel Bayesian regime-switching zero-inflated multilevel Poisson (RS-ZIMLP) regression model for forecasting alcohol use dynamics. The model partitions individuals’ data into two phases, known as regimes, with: (1) a zero-inflation regime that is used to accommodate high instances of zeros (non-drinking) and (2) a multilevel Poisson regression regime in which variations in individuals’ log-transformed average rates of alcohol use are captured by means of an autoregressive process with exogenous predictors and a person-specific intercept. The times at which individuals are in each regime are unknown, but may be estimated from the data. We assume that the regime indicator follows a first-order Markov process as related to exogenous predictors of interest. The forecast performance of the proposed model was evaluated using a Monte Carlo simulation study and further demonstrated using substance use and spatial covariate data from the Colorado Online Twin Study (CoTwins). Results showed that the proposed model yielded better forecast performance compared to a baseline model which predicted all cases as non-drinking and a reduced ZIMLP model without the RS structure, as indicated by higher AUC (the area under the receiver operating characteristic (ROC) curve) scores, and lower mean absolute errors (MAEs) and root-mean-square errors (RMSEs). The improvements in forecast performance were even more pronounced when we limited the comparisons to participants who showed at least one instance of transition to drinking. },
  publisher = {Springer Science and Business Media {LLC}},
  keywords = {Bayesian zero-inflated Poisson model, forecast, intensive longitudinal data, regime-switching, spatial data, substance use},
  annotation = {bayesian, ild},
}

@Article{Li-Wood-Ji-etal-2021,
  author = {Yanling Li and Julie Wood and Linying Ji and Sy-Miin Chow and Zita Oravecz},
  date = {2021-09},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {Fitting multilevel vector autoregressive models in {Stan}, {JAGS}, and {Mplus}},
  doi = {10.1080/10705511.2021.1911657},
  number = {3},
  pages = {452--475},
  volume = {29},
  abstract = {The influx of intensive longitudinal data creates a pressing need for complex modeling tools that help enrich our understanding of how individuals change over time. Multilevel vector autoregressive (mlVAR) models allow for simultaneous evaluations of reciprocal linkages between dynamic processes and individual differences, and have gained increased recognition in recent years. High-dimensional and other complex variations of mlVAR models, though often computationally intractable in the frequentist framework, can be readily handled using Markov chain Monte Carlo techniques in a Bayesian framework. However, researchers in social science fields may be unfamiliar with ways to capitalize on recent developments in Bayesian software programs. In this paper, we provide step-by-step illustrations and comparisons of options to fit Bayesian mlVAR models using Stan, JAGS and Mplus, supplemented with a Monte Carlo simulation study. An empirical example is used to demonstrate the utility of mlVAR models in studying intra- and inter-individual variations in affective dynamics.},
  publisher = {Informa {UK} Limited},
  keywords = {multilevel vector autoregressive models, Bayesian modeling, missing data, affective dynamics},
}

@Article{Loossens-Mestdagh-Dejonckheere-etal-2020,
  author = {Tim Loossens and Merijn Mestdagh and Egon Dejonckheere and Peter Kuppens and Francis Tuerlinckx and Stijn Verdonck},
  date = {2020-05},
  journaltitle = {PLOS Computational Biology},
  title = {The {Affective Ising Model}: A computational account of human affect dynamics},
  doi = {10.1371/journal.pcbi.1007860},
  editor = {Jacopo Grilli},
  issn = {1553-7358},
  number = {5},
  pages = {e1007860},
  volume = {16},
  abstract = {The human affect system is responsible for producing the positive and negative feelings that color and guide our lives. At the same time, when disrupted, its workings lie at the basis of the occurrence of mood disorder. Understanding the functioning and dynamics of the affect system is therefore crucial to understand the feelings that people experience on a daily basis, their dynamics across time, and how they can become dysregulated in mood disorder. In this paper, a nonlinear stochastic model for the dynamics of positive and negative affect is proposed called the Affective Ising Model (AIM). It incorporates principles of statistical mechanics, is inspired by neurophysiological and behavioral evidence about auto-excitation and mutual inhibition of the positive and negative affect dimensions, and is intended to better explain empirical phenomena such as skewness, multimodality, and non-linear relations of positive and negative affect. The AIM is applied to two large experience sampling studies on the occurrence of positive and negative affect in daily life in both normality and mood disorder. It is examined to what extent the model is able to reproduce the aforementioned non-Gaussian features observed in the data, using two sightly different continuous-time vector autoregressive (VAR) models as benchmarks. The predictive performance of the models is also compared by means of leave-one-out cross-validation. The results indicate that the AIM is better at reproducing non-Gaussian features while their performance is comparable for strictly Gaussian features. The predictive performance of the AIM is also shown to be better for the majority of the affect time series. The potential and limitations of the AIM as a computational model approximating the workings of the human affect system are discussed.},
  publisher = {Public Library of Science (PLoS)},
}

@Article{Loossens-Tuerlinckx-Verdonck-2021,
  author = {Tim Loossens and Francis Tuerlinckx and Stijn Verdonck},
  date = {2021-03},
  journaltitle = {Scientific Reports},
  title = {A comparison of continuous and discrete time modeling of affective processes in terms of predictive accuracy},
  doi = {10.1038/s41598-021-85320-4},
  issn = {2045-2322},
  number = {1},
  volume = {11},
  abstract = {Intra-individual processes are thought to continuously unfold across time. For equally spaced time intervals, the discrete-time lag-1 vector autoregressive (VAR(1)) model and the continuous-time Ornstein-Uhlenbeck (OU) model are equivalent. It is expected that by taking into account the unequal spacings of the time intervals in real data between observations will lead to an advantage for the OU in terms of predictive accuracy. In this paper, this is claim is being investigated by comparing the predictive accuracy of the OU model to that of the VAR(1) model on typical ESM data obtained in the context of affect research. It is shown that the VAR(1) model outperforms the OU model for the majority of the time series, even though time intervals in the data are unequally spaced. Accounting for measurement error does not change the result. Deleting large abrupt changes on short time intervals (that may be caused by externally driven events) does however lead to a significant improvement for the OU model. This suggests that processes in psychology may be continuously evolving, but that there are factors, like external events, which can disrupt the continuous flow.},
  publisher = {Springer Science and Business Media LLC},
}

@Article{Manthey-Hassan-Carr-etal-2021,
  author = {Jakob Manthey and Syed Ahmed Hassan and Sinclair Carr and Carolin Kilian and S{\"o}ren Kuitunen-Paul and J{\"u}rgen Rehm},
  date = {2021-05},
  journaltitle = {PharmacoEconomics},
  title = {What are the economic costs to society attributable to alcohol use? A systematic review and modelling study},
  doi = {10.1007/s40273-021-01031-8},
  issn = {1179-2027},
  number = {7},
  pages = {809--822},
  volume = {39},
  abstract = {Background: Alcohol-attributable costs to society are captured by cost-of-illness studies, however estimates are often not comparable, e.g. due to the omission of relevant cost components. In this contribution we (1) summarize the societal costs attributable to alcohol use, and (2) estimate the total costs under the assumption that all cost components are considered. Methods: A systematic review and meta-analyses were conducted for studies reporting costs from alcohol consumption for the years 2000 and later, using the EMBASE and MEDLINE databases. Cost estimates were converted into 2019 international dollars (Int\$) per adult and into percentage of gross domestic product (GDP). For each study, weights were calculated to correct for the exclusion of cost indicators. Results: Of 1708 studies identified, 29 were included, and the mean costs of alcohol use amounted to 817.6 Int\$ per adult (95\% confidence interval [CI] 601.8-1033.4), equivalent to 1.5\% of the GDP (95\% CI 1.2-1.7\%). Adjusting for omission of cost components, the economic costs of alcohol consumption were estimated to amount to 1306 Int\$ per adult (95\% CI 873-1738), or 2.6\% (95\% CI 2.0-3.1\%) of the GDP. About one-third of costs (38.8\%) were incurred through direct costs, while the majority of costs were due to losses in productivity (61.2\%). Discussion: The identified cost studies were mainly conducted in high-income settings, with high heterogeneity in the employed methodology. Accounting for some methodological variations, our findings demonstrate that alcohol use continues to incur a high level of cost to many societies.},
  publisher = {Springer Science and Business Media LLC},
}

@Article{McKendrick-Graziane-2020,
  author = {Greer McKendrick and Nicholas M. Graziane},
  date = {2020-09},
  journaltitle = {Frontiers in Behavioral Neuroscience},
  title = {Drug-induced conditioned place preference and its practical use in substance use disorder research},
  doi = {10.3389/fnbeh.2020.582147},
  issn = {1662-5153},
  volume = {14},
  abstract = {The conditioned place preference (CPP) paradigm is a well-established model utilized to study the role of context associations in reward-related behaviors, including both natural rewards and drugs of abuse. In this review article, we discuss the basic history, various uses, and considerations that are tied to this technique. There are many potential takeaway implications of this model, including negative affective states, conditioned drug effects, memory, and motivation, which are all considered here. We also discuss the neurobiology of CPP including relevant brain regions, molecular signaling cascades, and neuromodulatory systems. We further examine some of our prior findings and how they integrate CPP with self-administration paradigms. Overall, by describing the fundamentals of CPP, findings from the past few decades, and implications of using CPP as a research paradigm, we have endeavored to support the case that the CPP method is specifically advantageous for studying the role of a form of Pavlovian learning that associates drug use with the surrounding environment.},
  keywords = {conditioned place preference, CPP, drug reward, addiction-like behavior, drugs of abuse, substance use disorder, addiction, rodent model},
  publisher = {Frontiers Media SA},
}

@Article{McNeish-Hamaker-2020,
  author = {Daniel McNeish and Ellen L. Hamaker},
  date = {2020-10},
  journaltitle = {Psychological Methods},
  title = {A primer on two-level dynamic structural equation models for intensive longitudinal data in {Mplus}},
  doi = {10.1037/met0000250},
  number = {5},
  pages = {610--635},
  volume = {25},
  abstract = {Technological advances have led to an increase in intensive longitudinal data and the statistical literature on modeling such data is rapidly expanding, as are software capabilities. Common methods in this area are related to time-series analysis, a framework that historically has received little exposure in psychology. There is a scarcity of psychology-based resources introducing the basic ideas of time-series analysis, especially for data sets featuring multiple people. We begin with basics of N = 1 time-series analysis and build up to complex dynamic structural equation models available in the newest release of Mplus Version 8. The goal is to provide readers with a basic conceptual understanding of common models, template code, and result interpretation. We provide short descriptions of some advanced issues, but our main priority is to supply readers with a solid knowledge base so that the more advanced literature on the topic is more readily digestible to a larger group of researchers.},
  publisher = {American Psychological Association ({APA})},
  keywords = {dynamic structural equation modeling, time-series analysis, intensive longitudinal data, multilevel modeling},
}

@Article{McNeish-MacKinnon-2022,
  author = {Daniel McNeish and David P. MacKinnon},
  date = {2022-12},
  journaltitle = {Psychological Methods},
  title = {Intensive longitudinal mediation in {Mplus}},
  doi = {10.1037/met0000536},
  abstract = {Much of the existing longitudinal mediation literature focuses on panel data where relatively few repeated measures are collected over a relatively broad timespan. However, technological advances in data collection (e.g., smartphones, wearables) have led to a proliferation of short duration, densely collected longitudinal data in behavioral research. These intensive longitudinal data differ in structure and focus relative to traditionally collected panel data. As a result, existing methodological resources do not necessarily extend to nuances present in the recent influx of intensive longitudinal data and designs. In this tutorial, we first cover potential limitations of traditional longitudinal mediation models to accommodate unique characteristics of intensive longitudinal data. Then, we discuss how recently developed dynamic structural equation models (DSEMs) may be well-suited for mediation modeling with intensive longitudinal data and can overcome some of the limitations associated with traditional approaches. We describe four increasingly complex intensive longitudinal mediation models: (a) stationary models where the indirect effect is constant over time and people, (b) person-specific models where the indirect effect varies across people, (c) dynamic models where the indirect effect varies across time, and (d) cross-classified models where the indirect effect varies across both time and people. We apply each model to a running example featuring a mobile health intervention designed to improve health behavior of individuals with binge eating disorder. In each example, we provide annotated Mplus code and interpretation of the output to guide empirical researchers through mediation modeling with this increasingly popular type of longitudinal data.},
  publisher = {American Psychological Association ({APA})},
  keywords = {intensive longitudinal data, time-series, mediation, EMA, daily diary},
  annotation = {mediation, mediation-longitudinal},
}

@Article{Mulder-2022,
  author = {Jeroen D. Mulder},
  date = {2022-11},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {Power analysis for the random intercept cross-lagged panel model using the {powRICLPM R-package}},
  doi = {10.1080/10705511.2022.2122467},
  issn = {1532-8007},
  number = {4},
  pages = {645--658},
  volume = {30},
  abstract = {The random intercept cross-lagged panel model (RI-CLPM) is a popular model among psychologists for studying reciprocal effects in longitudinal panel data. Although various texts and software packages have been published concerning power analyses for structural equation models (SEM) generally, none have proposed a power analysis strategy that is tailored to the particularities of the RI-CLPM. This can be problematic because mismatches between the power analysis design, the model, and reality, can negatively impact the validity of the recommended sample size and number of repeated measures. As power analyses play an increasingly important role in the preparation phase of research projects, an RI-CLPM-specific strategy for the design of a power analysis is detailed, and implemented in the R-package powRICLPM. This paper focuses on the (basic) bivariate RI-CLPM, and extensions to include constraints over time, measurement error (leading to the stable trait autoregressive trait state model), non-normal data, and bounded estimation.},
  publisher = {Informa UK Limited},
}

@Article{Mulder-Hamaker-2020,
  author = {Jeroen D. Mulder and Ellen L. Hamaker},
  date = {2020-08},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {Three extensions of the random intercept cross-lagged panel model},
  doi = {10.1080/10705511.2020.1784738},
  issn = {1532-8007},
  number = {4},
  pages = {638--648},
  volume = {28},
  abstract = {The random intercept cross-lagged panel model (RI-CLPM) is rapidly gaining popularity in psychology and related fields as a structural equation modeling (SEM) approach to longitudinal data. It decomposes observed scores into within-unit dynamics and stable, between-unit differences. This paper discusses three extensions of the RI-CLPM that researchers may be interested in, but are unsure of how to accomplish: (a) including stable, person-level characteristics as predictors and/or outcomes; (b) specifying a multiple-group version; and (c) including multiple indicators. For each extension, we discuss which models need to be run in order to investigate underlying assumptions, and we demonstrate the various modeling options using a motivating example. We provide fully annotated code for lavaan (R-package) and Mplus on an accompanying website.},
  publisher = {Informa UK Limited},
}

@Article{Muthen-Asparouhov-2022,
  author = {Bengt O. Muth{\a'e}n and Tihomir Asparouhov},
  date = {2022-02},
  journaltitle = {Psychological Methods},
  title = {Latent transition analysis with random intercepts ({RI-LTA})},
  doi = {10.1037/met0000370},
  issn = {1082-989X},
  number = {1},
  pages = {1--16},
  volume = {27},
  abstract = {This article demonstrates that the regular LTA model is unnecessarily restrictive and that an alternative model is readily available that typically fits the data much better, leads to better estimates of the transition probabilities, and extracts new information from the data. By allowing random intercept variation in the model, between-subject variation is separated from the within-subject latent class transitions over time allowing a clearer interpretation of the data. Analysis of two examples from the literature demonstrates the advantages of random intercept LTA. Model variations include Mover-Stayer analysis, measurement invariance analysis, and analysis with covariates.},
  publisher = {American Psychological Association (APA)},
}

@Article{Norman-Peacock-Ferguson-etal-2020,
  author = {Thomas Norman and Amy Peacock and Stuart G. Ferguson and Emmanuel Kuntsche and Raimondo Bruno},
  date = {2020-11},
  journaltitle = {Drug and Alcohol Review},
  title = {Combining transdermal and breath alcohol assessments, real‐time drink logs and retrospective self‐reports to measure alcohol consumption and intoxication across a multi‐day music festival},
  doi = {10.1111/dar.13215},
  issn = {1465-3362},
  number = {7},
  pages = {1112--1121},
  volume = {40},
  abstract = {Introduction and Aims: Comprehensively investigating alcohol-related behaviours in the context of a dynamic multi-day alcohol-licensed event is important for understanding and minimising patron risk. We aimed to assess the measurement utility of implementing a multi-dimensional alcohol assessment battery using biometric data collection, real-time drink logs and retrospective self-report measures over the course of a 4-day music festival. Methods: Fourteen adults participated ($n = 7$ male, mean age 21.9 years). Breath and transdermal alcohol concentration (BrAC and TAC, respectively) were measured using breathalysers and transdermal alcohol bracelets. A real-time drink log was completed via smartphones on initiating each drink, and a retrospective questionnaire was administered up to twice daily throughout the event (6 timepoints total). Results: While almost all participants (92.9\%) logged significantly fewer drinks in real-time than they retrospectively reported via the twice-daily questionnaires, logs provided important contextual information including the types of drinks consumed and drinking intensity. Compared to BrAC, TAC provided a better understanding of the time course of intoxication, indicating highest alcohol consumption outside of static BrAC assessment windows. However, BrAC provided a better assessment of present state: all participants were 0.00\% BrAC at departure despite over two-fifths (42.9\%) of the sample's last TAC reading exceeding 0.00\%. Conclusions: As standalone assessments, each method possessed limitations. As a combined battery, they were successfully administered simultaneously, resulting in a more comprehensive overview of alcohol consumption/intoxication over the prolonged drinking session. However, the marked burden of simultaneous administration should be considered, and measures should be chosen judiciously based on research needs.},
  publisher = {Wiley},
}

@Article{Nust-Eddelbuettel-Bennett-etal-2020,
  author = {Daniel N{\"u}st and Dirk Eddelbuettel and Dom Bennett and Robrecht Cannoodt and Dav Clark and Gergely Dar{\a'o}czi and Mark Edmondson and Colin Fay and Ellis Hughes and Lars Kjeldgaard and Sean Lopp and Ben Marwick and Heather Nolis and Jacqueline Nolis and Hong Ooi and Karthik Ram and Noam Ross and Lori Shepherd and P{\a'e}ter S{\a'o}lymos and Tyson Lee Swetnam and Nitesh Turaga and Charlotte {Van Petegem} and Jason Williams and Craig Willis and Nan Xiao},
  date = {2020},
  journaltitle = {The R Journal},
  title = {The {Rockerverse}: Packages and applications for containerisation with {R}},
  doi = {10.32614/rj-2020-007},
  number = {1},
  pages = {437},
  volume = {12},
  abstract = {The Rocker Project provides widely used Docker images for R across different application scenarios. This article surveys downstream projects that build upon the Rocker Project images and presents the current state of R packages for managing Docker images and controlling containers. These use cases cover diverse topics such as package development, reproducible research, collaborative work, cloud-based data processing, and production deployment of services. The variety of applications demonstrates the power of the Rocker Project specifically and containerisation in general. Across the diverse ways to use containers, we identified common themes: reproducible environments, scalability and efficiency, and portability across clouds. We conclude that the current growth and diversification of use cases is likely to continue its positive impact, but see the need for consolidating the Rockerverse ecosystem of packages, developing common practices for applications, and exploring alternative containerisation software.},
  publisher = {The R Foundation},
  annotation = {container, container-docker, container-rocker},
}

@Article{Oh-Hunter-Chow-2025,
  author = {Hyungeun Oh and Michael D. Hunter and Sy-Miin Chow},
  date = {2025-02},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {Measurement model misspecification in dynamic structural equation models: Power, reliability, and other considerations},
  doi = {10.1080/10705511.2025.2452884},
  issn = {1532-8007},
  pages = {1--18},
  abstract = {Dynamic Structural Equation Models (DSEMs) integrate multilevel modeling, time series analysis, and structural equation modeling within a Bayesian estimation framework, offering a versatile tool for analyzing intensive longitudinal data (ILD). However, the impact of measurement structure misspecification in DSEMs, especially under varying reliability conditions and model complexities, remains underexplored. Our Monte Carlo simulation revealed that omitting measurement errors when present led to severe biases in dynamic parameters regardless of reliability conditions, though power remained high. Increasing the number of participants and time points ameliorated but did not eliminate all biases. A single-indicator DSEMs with a measurement structure using composite scores showed similar performance to multiple indicators DSEMs. Empirical applications showed discrepancies in dynamic parameters based on the number of indicators and measurement structures used. Leveraging these findings, we provide design recommendations, functions for extending reliability indices from single-indicator to multiple-indicator models, and guidelines for power evaluations under different reliability conditions.},
  publisher = {Informa UK Limited},
}

@Article{Orth-Clark-Donnellan-etal-2021,
  author = {Ulrich Orth and D. Angus Clark and M. Brent Donnellan and Richard W. Robins},
  date = {2021-04},
  journaltitle = {Journal of Personality and Social Psychology},
  title = {Testing prospective effects in longitudinal research: Comparing seven competing cross-lagged models},
  doi = {10.1037/pspp0000358},
  issn = {0022-3514},
  number = {4},
  pages = {1013--1034},
  volume = {120},
  abstract = {In virtually all areas of psychology, the question of whether a particular construct has a prospective effect on another is of fundamental importance. For decades, the cross-lagged panel model (CLPM) has been the model of choice for addressing this question. However, CLPMs have recently been critiqued, and numerous alternative models have been proposed. Using the association between low self-esteem and depression as a case study, we examined the behavior of seven competing longitudinal models in 10 samples, each with at least four waves of data and sample sizes ranging from 326 to 8,259. The models were compared in terms of convergence, fit statistics, and consistency of parameter estimates. The traditional CLPM and the random intercepts cross-lagged panel model (RI-CLPM) converged in every sample, whereas the other models frequently failed to converge or did not converge properly. The RI-CLPM exhibited better model fit than the CLPM, whereas the CLPM produced more consistent cross-lagged effects (both across and within samples) than the RI-CLPM. We discuss the models from a conceptual perspective, emphasizing that the models test conceptually distinct psychological and developmental processes, and we address the implications of the empirical findings with regard to model selection. Moreover, we provide practical recommendations for researchers interested in testing prospective associations between constructs and suggest using the CLPM when focused on between-person effects and the RI-CLPM when focused on within-person effects.},
  publisher = {American Psychological Association (APA)},
}

@Article{Orzek-Voelkle-2023,
  author = {Jannik H. Orzek and Manuel C. Voelkle},
  date = {2023-12},
  journaltitle = {Psychological Methods},
  title = {Regularized continuous time structural equation models: A network perspective},
  doi = {10.1037/met0000550},
  issn = {1082-989X},
  number = {6},
  pages = {1286--1320},
  volume = {28},
  abstract = {Regularized continuous time structural equation models are proposed to address two recent challenges in longitudinal research: Unequally spaced measurement occasions and high model complexity. Unequally spaced measurement occasions are part of most longitudinal studies, sometimes intentionally (e.g., in experience sampling methods) sometimes unintentionally (e.g., due to missing data). Yet, prominent dynamic models, such as the autoregressive cross-lagged model, assume equally spaced measurement occasions. If this assumption is violated parameter estimates can be biased, potentially leading to false conclusions. Continuous time structural equation models (CTSEM) resolve this problem by taking the exact time point of a measurement into account. This allows for any arbitrary measurement scheme. We combine CTSEM with LASSO and adaptive LASSO regularization. Such regularization techniques are especially promising for the increasingly complex models in psychological research, the most prominent example being network models with often dozens or hundreds of parameters. Here, LASSO regularization can reduce the risk of overfitting and simplify the model interpretation. In this article we highlight unique challenges in regularizing continuous time dynamic models, such as standardization or the optimization of the objective function, and offer different solutions. Our approach is implemented in the R (R Core Team, 2022) package regCtsem. We demonstrate the use of regCtsem in a simulation study, showing that the proposed regularization improves the parameter estimates, especially in small samples. The approach correctly eliminates true-zero parameters while retaining true-nonzero parameters. We present two empirical examples and end with a discussion on current limitations and future research directions.},
  publisher = {American Psychological Association (APA)},
}

@Article{Park-Chow-Epskamp-etal-2024,
  author = {Jonathan J. Park and Sy-Miin Chow and Sacha Epskamp and Peter C. M. Molenaar},
  date = {2024-02},
  journaltitle = {Multivariate Behavioral Research},
  title = {Subgrouping with chain graphical {VAR} models},
  doi = {10.1080/00273171.2023.2289058},
  issn = {1532-7906},
  number = {3},
  pages = {543--565},
  volume = {59},
  abstract = {Recent years have seen the emergence of an ``idio-thetic'' class of methods to bridge the gap between nomothetic and idiographic inference. These methods describe nomothetic trends in idiographic processes by pooling intraindividual information across individuals to inform group-level inference or vice versa. The current work introduces a novel ``idio-thetic'' model: the subgrouped chain graphical vector autoregression (scGVAR). The scGVAR is unique in its ability to identify subgroups of individuals who share common dynamic network structures in both lag(1) and contemporaneous effects. Results from Monte Carlo simulations indicate that the scGVAR shows promise over similar approaches when clusters of individuals differ in their contemporaneous dynamics and in showing increased sensitivity in detecting nuanced group differences while keeping Type-I error rates low. In contrast, a competing approach–the Alternating Least Squares VAR (ALS VAR) performs well when groups were separated by larger distances. Further considerations are provided regarding applications of the ALS VAR and scGVAR on real data and the strengths and limitations of both methods.},
  publisher = {Informa UK Limited},
}

@Article{Park-Fisher-Chow-etal-2023a,
  author = {Jonathan J. Park and Zachary Fisher and Sy-Miin Chow and Peter C. M. Molenaar},
  date = {2023-01},
  journaltitle = {Multivariate Behavioral Research},
  title = {On subgrouping continuous processes in discrete time},
  doi = {10.1080/00273171.2022.2160957},
  issn = {1532-7906},
  number = {1},
  pages = {154--155},
  volume = {58},
  publisher = {Informa UK Limited},
}

@Article{Park-Fisher-Chow-etal-2023b,
  author = {Jonathan J. Park and Zachary F. Fisher and Sy-Miin Chow and Peter C. M. Molenaar},
  date = {2023-08},
  journaltitle = {Multivariate Behavioral Research},
  title = {Evaluating discrete time methods for subgrouping continuous processes},
  doi = {10.1080/00273171.2023.2235685},
  issn = {1532-7906},
  pages = {1--13},
  abstract = {Rapid developments over the last several decades have brought increased focus and attention to the role of time scales and heterogeneity in the modeling of human processes. To address these emerging questions, subgrouping methods developed in the discrete-time framework—such as the vector autoregression (VAR)—have undergone widespread development to identify shared nomothetic trends from idiographic modeling results. Given the dependence of VAR-based parameters on the measurement intervals of the data, we sought to clarify the strengths and limitations of these methods in recovering subgroup dynamics under different measurement intervals. Building on the work of Molenaar and collaborators for subgrouping individual time-series by means of the subgrouped chain graphical VAR (scgVAR) and the subgrouping option in the group iterative multiple model estimation (S-GIMME), we present results from a Monte Carlo study aimed at addressing the implications of identifying subgroups using these discrete-time methods when applied to continuous-time data. Results indicate that discrete-time subgrouping methods perform well at recovering true subgroups when the measurement intervals are large enough to capture the full range of a system’s dynamics, either via lagged or contemporaneous effects. Further implications and limitations are discussed therein.},
  publisher = {Informa UK Limited},
}

@Article{Pesigan-Cheung-2020,
  author = {Ivan Jacob Agaloos Pesigan and Shu Fai Cheung},
  date = {2020-12},
  journaltitle = {Frontiers in Psychology},
  title = {{SEM}-based methods to form confidence intervals for indirect effect: Still applicable given nonnormality, under certain conditions},
  doi = {10.3389/fpsyg.2020.571928},
  volume = {11},
  abstract = {A SEM-based approach using likelihood-based confidence interval (LBCI) has been proposed to form confidence intervals for unstandardized and standardized indirect effect in mediation models. However, when used with the maximum likelihood estimation, this approach requires that the variables are multivariate normally distributed. This can affect the LBCIs of unstandardized and standardized effect differently. In the present study, the robustness of this approach when the predictor is not normally distributed but the error terms are conditionally normal, which does not violate the distributional assumption of ordinary least squares (OLS) estimation, is compared to four other approaches: nonparametric bootstrapping, two variants of LBCI, LBCI assuming the predictor is fixed (LBCI-Fixed-X) and LBCI based on ADF estimation (LBCI-ADF), and Monte Carlo. A simulation study was conducted using a simple mediation model and a serial mediation model, manipulating the distribution of the predictor. The Monte Carlo method performed worst among the methods. LBCI and LBCI-Fixed-X had suboptimal performance when the distributions had high kurtosis and the population indirect effects were medium to large. In some conditions, the problem was severe even when the sample size was large. LBCI-ADF and nonparametric bootstrapping had coverage probabilities close to the nominal value in nearly all conditions, although the coverage probabilities were still suboptimal for the serial mediation model when the sample size was small with respect to the model. Implications of these findings in the context of this special case of nonnormal data were discussed.},
  publisher = {Frontiers Media {SA}},
  keywords = {mediation, nonnormal, confidence interval, structural equation modeling, bootstrapping},
  annotation = {mediation, mediation-likelihood, mediation-bootstrap, mediation-montecarlo},
}

@Article{Pesigan-Cheung-2023,
  author = {Ivan Jacob Agaloos Pesigan and Shu Fai Cheung},
  date = {2023-08},
  journaltitle = {Behavior Research Methods},
  title = {{Monte Carlo} confidence intervals for the indirect effect with missing data},
  doi = {10.3758/s13428-023-02114-4},
  number = {3},
  pages = {1678--1696},
  volume = {56},
  abstract = {Missing data is a common occurrence in mediation analysis. As a result, the methods used to construct confidence intervals around the indirect effect should consider missing data. Previous research has demonstrated that, for the indirect effect in data with complete cases, the Monte Carlo method performs as well as nonparametric bootstrap confidence intervals (see MacKinnon et al., Multivariate Behavioral Research, 39(1), 99–128, 2004; Preacher \& Selig, Communication Methods and Measures, 6(2), 77–98, 2012; Tofighi \& MacKinnon, Structural Equation Modeling: A Multidisciplinary Journal, 23(2), 194–205, 2015). In this manuscript, we propose a simple, fast, and accurate two-step approach for generating confidence intervals for the indirect effect, in the presence of missing data, based on the Monte Carlo method. In the first step, an appropriate method, for example, full-information maximum likelihood or multiple imputation, is used to estimate the parameters and their corresponding sampling variance-covariance matrix in a mediation model. In the second step, the sampling distribution of the indirect effect is simulated using estimates from the first step. A confidence interval is constructed from the resulting sampling distribution. A simulation study with various conditions is presented. Implications of the results for applied research are discussed.},
  publisher = {Springer Science and Business Media {LLC}},
  keywords = {Monte Carlo method, nonparametric bootstrap, indirect effect, mediation, missing completely at random, missing at random, full-information maximum likelihood, multiple imputation},
  annotation = {mediation, mediation-missing, mediation-bootstrap, mediation-montecarlo, mediation-jointtest, sem, r, r-packages},
}

@Article{Pesigan-Sun-Cheung-2023,
  author = {Ivan Jacob Agaloos Pesigan and Rong Wei Sun and Shu Fai Cheung},
  date = {2023-04},
  journaltitle = {Multivariate Behavioral Research},
  title = {{betaDelta} and {betaSandwich}: Confidence intervals for standardized regression coefficients in {R}},
  doi = {10.1080/00273171.2023.2201277},
  number = {6},
  pages = {1183--1186},
  volume = {58},
  abstract = {The multivariate delta method was used by Yuan and Chan to estimate standard errors and confidence intervals for standardized regression coefficients. Jones and Waller extended the earlier work to situations where data are nonnormal by utilizing Browne’s asymptotic distribution-free (ADF) theory. Furthermore, Dudgeon developed standard errors and confidence intervals, employing heteroskedasticity-consistent (HC) estimators, that are robust to nonnormality with better performance in smaller sample sizes compared to Jones and Waller’s ADF technique. Despite these advancements, empirical research has been slow to adopt these methodologies. This can be a result of the dearth of user-friendly software programs to put these techniques to use. We present the betaDelta and the betaSandwich packages in the R statistical software environment in this manuscript. Both the normal-theory approach and the ADF approach put forth by Yuan and Chan and Jones and Waller are implemented by the betaDelta package. The HC approach proposed by Dudgeon is implemented by the betaSandwich package. The use of the packages is demonstrated with an empirical example. We think the packages will enable applied researchers to accurately assess the sampling variability of standardized regression coefficients.},
  publisher = {Informa {UK} Limited},
  keywords = {standardized regression coefficients, confidence intervals, delta method standard errors, heteroskedasticity-consistent standard errors, R package},
  annotation = {r, r-packages},
}

@Article{Ray-Du-Grodin-etal-2020,
  author = {Lara A. Ray and Han Du and Erica Grodin and Spencer Bujarski and Lindsay Meredith and Diana Ho and Steven Nieto and Kate Wassum},
  date = {2020-02},
  journaltitle = {Drug and Alcohol Dependence},
  title = {Capturing habitualness of drinking and smoking behavior in humans},
  doi = {10.1016/j.drugalcdep.2019.107738},
  issn = {0376-8716},
  pages = {107738},
  volume = {207},
  abstract = {Background: Recent findings suggest that overreliance on habit may be common in individuals diagnosed with addiction. To advance our understanding of habit in clinical samples and from behavioral measures, this study examines the interrelations between self-reported habit index for smoking and drinking as well as behavioral measures of intraindividual variability in smoking and drinking. Methods: Treatment-seeking heavy drinking smokers ($N = 416$) completed the Self-Report Habit Index (SRHI) adapted for both smoking and drinking. ``Behavioral habitualness'' was computed from the degree of intraindividual variability in patterns of smoking and drinking over the past month. Using the 28-day Timeline-Follow Back (TLFB) interview, we derived two measures of intraindividual variability: interclass correlation (ICC) and autocorrelation [AR(7) coefficients]. Results: Self-report measures of habit were robustly associated with clinical severity of drinking and smoking with higher habit scores indicating greater severity of drinking and smoking, respectively. ICC and AR(7) coefficients, the behavioral measure of “patterness” and putative habit, were not associated with SRHI scores. While ICC for smoking was associated with higher nicotine dependence scores, this pattern was not found for drinking ICC and alcohol problem severity.
Conclusions: These results support the construct validity of the self-report measures of habit for smoking and drinking, as well an initial evaluation of behavioral measure of smoking ``patterness'' as a potential proxy for habit smoking. Because habit represents a complex phenotype with limited clinical translation, additional studies capturing a wider range of substance use severity and coupled with brain-based validation methods are warranted.},
  keyword = {habit, alcohol, cigarette, smoking, drinking, human},
  publisher = {Elsevier BV},
}

@Article{Rhemtulla-vanBork-Borsboom-2020,
  author = {Mijke Rhemtulla and Riet {van Bork} and Denny Borsboom},
  date = {2020-02},
  journaltitle = {Psychological Methods},
  title = {Worse than measurement error: Consequences of inappropriate latent variable measurement models},
  doi = {10.1037/met0000220},
  issn = {1082-989X},
  number = {1},
  pages = {30--45},
  volume = {25},
  abstract = {Previous research and methodological advice has focused on the importance of accounting for measurement error in psychological data. That perspective assumes that psychological variables conform to a common factor model. We explore what happens when data that are not generated from a common factor model are nonetheless modeled as reflecting a common factor. Through a series of hypothetical examples and an empirical reanalysis, we show that when a common factor model is misused, structural parameter estimates that indicate the relations among psychological constructs can be severely biased. Moreover, this bias can arise even when model fit is perfect. In some situations, composite models perform better than common factor models. These demonstrations point to a need for models to be justified on substantive, theoretical bases in addition to statistical ones.},
  publisher = {American Psychological Association (APA)},
}

@Article{Richards-Barnett-Cook-etal-2022,
  author = {Veronica L. Richards and Nancy P. Barnett and Robert L. Cook and Robert F. Leeman and Timothy Souza and Stuart Case and Cindy Prins and Christa Cook and Yan Wang},
  date = {2022-12},
  journaltitle = {Alcohol: Clinical and Experimental Research},
  title = {Correspondence between alcohol use measured by a wrist‐worn alcohol biosensor and self‐report via ecological momentary assessment over a 2‐week period},
  doi = {10.1111/acer.14995},
  issn = {2993-7175},
  number = {2},
  pages = {308--318},
  volume = {47},
  abstract = {Background: Transdermal alcohol biosensors measure alcohol use continuously, passively, and non-invasively. There is little field research on the Skyn biosensor, a new-generation, wrist-worn transdermal alcohol biosensor, and little evaluation of its sensitivity and specificity and the day-level correspondence between transdermal alcohol concentration (TAC) and number of self-reported drinks. Methods: Participants ($N = 36$; 61\% male, $M_{age} = 34.3$) wore the Skyn biosensor and completed ecological momentary assessment (EMA) surveys about their alcohol use over 2 weeks. A total of 497 days of biosensor and EMA data were collected. Skyn-measured drinking episodes were defined by TAC > $5 \mu g / L$. Skyn data were compared to self-reported drinking to calculate sensitivity and specificity (for drinking day vs. nondrinking day). Generalized estimating equations models were used to evaluate the correspondence between TAC features (peak TAC and TAC-area under the curve (AUC)) and number of drinks. Individual-level factors (sex, age, race/ethnicity, body mass index, human immunodeficiency virus status, and hazardous drinking) were examined to explore associations with TAC controlling for number of drinks. Results: Using a minimum TAC threshold of $5 \mu g / L$ plus coder review, the biosensor had sensitivity of 54.7\% and specificity of 94.6\% for distinguishing drinking from nondrinking days. Without coder review, the sensitivity was 78.1\% and the specificity was 55.2\%. Peak TAC ($\beta = 0.92, p < 0.0001$) and TAC-AUC ($\beta = 1.60, p < 0.0001$) were significantly associated with number of drinks. Females had significantly higher TAC levels than males for the same number of drinks. Conclusions:  Skyn-derived TAC can be used to measure alcohol use under naturalistic drinking conditions, additional research is needed to accurately identify drinking episodes based on Skyn TAC readings.},
  publisher = {Wiley},
}

@Article{Richards-Glenn-Turrisi-etal-2024,
  author = {Veronica L. Richards and Shannon D. Glenn and Robert J. Turrisi and Kimberly A. Mallett and Sarah Ackerman and Michael A. Russell},
  date = {2024-04},
  journaltitle = {Alcohol, Clinical and Experimental Research},
  title = {Transdermal alcohol concentration features predict alcohol‐induced blackouts in college students},
  doi = {10.1111/acer.15290},
  issn = {2993-7175},
  number = {5},
  pages = {880--888},
  volume = {48},
  abstract = {Background: Alcohol-induced blackouts (AIBs) are common in college students. Individuals with AIBs also experience acute and chronic alcohol-related consequences. Research suggests that how students drink is an important predictor of AIBs. We used transdermal alcohol concentration (TAC) sensors to measure biomarkers of increasing alcohol intoxication (rise rate, peak, and rise duration) in a sample of college students. We hypothesized that the TAC biomarkers would be positively associated with AIBs. Methods: Students were eligible to participate if they were aged 18-22 years, in their second or third year of college, reported drinking 4+ drinks on a typical Friday or Saturday, experienced $\geq 1$ AIB in the past semester, owned an iPhone, and were willing to wear a sensor for 3 days each weekend. Students ($N = 79$, $55.7\%$ female, $86.1\%$ White, $M_{age} = 20.1$) wore TAC sensors and completed daily diaries over four consecutive weekends (89.9\% completion rate). AIBs were assessed using the Alcohol-Induced Blackout Measure-2. Logistic multilevel models were conducted to test for main effects. Results: Days with faster TAC rise rates (OR = 2.69, $95\%$ CI: 1.56, 5.90), higher peak TACs (OR = 2.93, $95\%$ CI: 1.64, 7.11), and longer rise TAC durations (OR = 4.16, $95\%$ CI: 2.08, 10.62) were associated with greater odds of experiencing an AIB. Conclusions: In a sample of ``risky'' drinking college students, three TAC drinking features identified as being related to rising intoxication independently predicted the risk for daily AIBs. Our findings suggest that considering how an individual drinks (assessed using TAC biomarkers), rather than quantity alone, is important for assessing risk and has implications for efforts to reduce risk. Not only is speed of intoxication important for predicting AIBs, but the height of the peak intoxication and the time spent reaching the peak are important predictors, each with different implications for prevention.},
  publisher = {Wiley},
}

@Article{Richards-Mallett-Turrisi-etal-2025,
  author = {Veronica L. Richards and Kimberly A. Mallett and Robert J. Turrisi and Shannon D. Glenn and Michael A. Russell},
  date = {2025-01},
  journaltitle = {Psychology of Addictive Behaviors},
  title = {Profiles of transdermal alcohol concentration and their prediction of negative and positive alcohol-related consequences in young adults’ natural settings},
  doi = {10.1037/adb0001054},
  issn = {0893-164X},
  abstract = {Objective: Transdermal alcohol concentration (TAC) sensors provide a multidimensional characterization of drinking events that self-reports cannot. These profiles may differ in their associated day-level alcohol-related consequences, but no research has tested this. We address this using multilevel latent profile analysis. Method: Two hundred twenty-two young adults who regularly engage in heavy drinking ($M_{\mathrm{age}} = 22.3$, $64\%$ female, $79\%$ non-Hispanic White) responded to surveys and wore TAC sensors for 6 consecutive days. We tested whether four previously identified TAC profiles: (1) high-fast ($8.5\%$ of days), (2) moderate-fast ($12.8\%$), (3) low-slow ($20.4\%$), and (4) little-to-no-drinking days ($58.2\%$) differed in numbers of negative and positive consequences and in the odds that both consequence types occurred on the same day. Results: High-fast (incident rate ratio [$\mathrm{IRR}_{\mathrm{low-slow}}] = 6.18$; $\mathrm{IRR}_{\mathrm{little-to-no-drinking}} = 9.47$) and moderate-fast ($\mathrm{IRR}_{\mathrm{low-slow}} = 3.71$; $\mathrm{IRR}_{\mathrm{little-to-no-drinking}} = 5.68$) days contained more negative consequences compared to low-slow and little-to-no-drinking days. High-fast ($\mathrm{IRR} = 2.05$), moderate-fast ($\mathrm{IRR} = 1.88$), and low-slow ($\mathrm{IRR} = 1.43$) days contained more positive consequences than little-to-no-drinking days. The odds of having only positive consequences were highest on low-slow, $\chi^{2}(3) = 9.10$, $p < .05$, days but the odds of experiencing both consequence types increased on moderate-fast and high-fast days, $\chi^{2}(3) = 39.63$, $p < .001$. Conclusions: Compared to little-to-no-drinking days, TAC profiles indicative of drinking (high-fast, moderate-fast, and low-slow) contained more negative and positive consequences. However, the odds of experiencing only positive consequences were highest among low-slow days and decreased on moderate-fast and high-fast days as the odds of negative consequences rose. These findings provide novel evidence reinforcing harm reduction approaches that seek to maximize positives and minimize negatives of alcohol consumption through emphasis on slow-paced, low-volume drinking.},
  publisher = {American Psychological Association (APA)},
}

@Article{Richards-Turrisi-Russell-2024,
  author = {Veronica L. Richards and Robert J. Turrisi and Michael A. Russell},
  date = {2024-05},
  journaltitle = {Psychology of Addictive Behaviors},
  title = {Subjective intoxication predicts alcohol-related consequences at equivalent alcohol concentrations in young adults using ecological momentary assessment and alcohol sensors},
  doi = {10.1037/adb0000993},
  issn = {0893-164X},
  number = {3},
  pages = {334--346},
  volume = {38},
  abstract = {Objective: Subjective intoxication (SI) when drinking may serve as an internal barometer of whether to continue drinking or engage in potentially unsafe behavior. Mobile assessments offer the potential to use SI as a prospective risk indicator during drinking episodes; little evidence exists for the validity of real-time SI measures. We test the correspondence of SI with estimated blood alcohol concentration and transdermal alcohol concentration (TAC) in young adults' natural settings. We provide a novel test of whether SI features (peak and mean SI) uniquely predict consequences adjusting for alcohol concentration. Method: Two hundred twenty-two heavy-drinking young adults ($M_{age} = 22.3$, 64\% female, 79\% non-Hispanic White, 84\% undergraduates) participated in a 6-day study that used ecological momentary assessment of drinking and TAC sensors. SI was assessed every 30 min during drinking episodes. Multilevel modeling was used to test hypotheses. Results: Momentary SI and estimated blood alcohol concentration had moderate associations at the moment and day levels (standardized $\beta$s = 0.5-0.6); SI was moderately associated with TAC at the day level ($\beta$s = 0.5). Associations between SI and alcohol concentration varied widely between persons and across days. Day-level SI features predicted consequences when adjusting for alcohol concentration (incidence rate ratios, IRRs = 1.29–1.70). Conclusions: Our two-item SI measure shows evidence of validity in real-world settings with heavy-drinking young adults. SI was significantly correlated with alcohol concentration and was a unique predictor of consequences. The strength of these associations varied greatly across persons and days. Real-time SI measurement may be useful in preventive interventions, but continued research is needed into when and for whom momentary SI is most predictive of risk.},
  publisher = {American Psychological Association (APA)},
}

@Article{Rousselet-Pernet-Wilcox-2021,
  author = {Guillaume A. Rousselet and Cyril R. Pernet and Rand R. Wilcox},
  date = {2021-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  title = {The percentile bootstrap: A primer with step-by-step instructions in {R}},
  doi = {10.1177/2515245920911881},
  number = {1},
  pages = {1--10},
  volume = {4},
  abstract = {The percentile bootstrap is the Swiss Army knife of statistics: It is a nonparametric method based on data-driven simulations. It can be applied to many statistical problems, as a substitute to standard parametric approaches, or in situations for which parametric methods do not exist. In this Tutorial, we cover \texttt{R} code to implement the percentile bootstrap to make inferences about central tendency (e.g., means and trimmed means) and spread in a one-sample example and in an example comparing two independent groups. For each example, we explain how to derive a bootstrap distribution and how to get a confidence interval and a $p$ value from that distribution. We also demonstrate how to run a simulation to assess the behavior of the bootstrap. For some purposes, such as making inferences about the mean, the bootstrap performs poorly. But for other purposes, it is the only known method that works well over a broad range of situations. More broadly, combining the percentile bootstrap with robust estimators (i.e., estimators that are not overly sensitive to outliers) can help users gain a deeper understanding of their data than they would using conventional methods.},
  publisher = {{SAGE} Publications},
  keywords = {bootstrap, confidence interval, correlation, R, simulation, trimmed mean, median, reaction time, skewness, group comparison, open materials},
}

@Article{Russell-LindenCarmichael-Lanza-etal-2020,
  author = {Michael A. Russell and Ashley N. Linden-Carmichael and Stephanie T. Lanza and Emily V. Fair and Kenneth J. Sher and Thomas M. Piasecki},
  date = {2020-05},
  journaltitle = {Psychology of Addictive Behaviors},
  title = {Affect relative to day-level drinking initiation: Analyzing ecological momentary assessment data with multilevel spline modeling},
  doi = {10.1037/adb0000550},
  issn = {0893-164X},
  number = {3},
  pages = {434--446},
  volume = {34},
  abstract = {Affect regulation models state that affect both motivates and reinforces alcohol use. We aimed to examine whether affect levels and rates of change differed across drinking versus nondrinking days in a manner consistent with affect regulation models. Four hundred four regularly drinking adults, aged 18–70 years, completed ecological momentary assessments over 3 weeks. Participants provided positive affect (PA; enthusiastic, excited, happy) and negative affect (NA; distressed, sad) reports during all prompts; alcohol consumption reports were also provided. Multilevel spline models revealed that on drinking days, PA was higher and NA was lower both before and after drinking compared to matched times on nondrinking days. PA and NA were also higher and lower, respectively, both before and after drinking, when heavy drinking days were compared to moderate drinking days. Examination of affect rates of change revealed that (a) accelerating increases in PA and accelerating decreases in NA preceded drinking initiation, (b) PA increases and NA decreases were seen up to 2 hr after drinking initiation, and (c) pre- and postdrinking PA increases were larger on heavy versus moderate drinking days, whereas only postdrinking NA decreases were larger on heavy drinking days. Results supported affect regulation models while adding nuance, showing accelerating changes in predrinking affect on drinking days and pre- and postdrinking differences in affect levels and rates of change across days of varying drinking intensity. Beyond theory, our results suggest that accelerating changes in affect may provide a clue to future commencement of heavy drinking, which may aid momentary intervention development.},
  publisher = {American Psychological Association (APA)},
}

@Article{Russell-Richards-Turrisi-etal-2024,
  author = {Michael A. Russell and Veronica L. Richards and Robert J. Turrisi and Cara L. Exten and Ivan Jacob Agaloos Pesigan and Gabriel C. Rodriguez},
  date = {2024-08},
  journaltitle = {Psychology of Addictive Behaviors},
  title = {Profiles of alcohol intoxication and their associated risks in young adults’ natural settings: A multilevel latent profile analysis applied to daily transdermal alcohol concentration data},
  doi = {10.1037/adb0001022},
  issn = {0893-164X},
  abstract = {Objective: Transdermal alcohol concentration (TAC) sensors capture aspects of drinking events that self-reports cannot. The multidimensional nature of TAC data allows novel classification of drinking days and identification of associated behavioral and contextual risks. We used multilevel latent profile analysis (MLPA) to create day-level profiles of TAC features and test their associations with (a) daily behaviors and contexts and (b) risk for alcohol use disorders at baseline. Method: Two hundred twenty-two regularly heavy-drinking young adults (Mage = 22.3) completed the Alcohol Use Disorders Identification Test (AUDIT) at baseline and then responded to mobile phone surveys and wore TAC sensors for six consecutive days. MLPA identified day-level profiles using four TAC features (peak, rise rate, fall rate, and duration). TAC profiles were tested as correlates of daily drinking behaviors, contexts, and baseline AUDIT. Results: Four profiles emerged: (a) high-fast (8.5\% of days), (b) moderate-fast (12.8\%), (c) low-slow (20.4\%), and (d) little-to-no drinking days (58.2\%). Profiles differed in the odds of risky drinking behaviors and contexts. The highest risk occurred on high-fast days, followed by moderate-fast, low-slow, and little-to-no drinking days. Higher baseline AUDIT predicted higher odds of high-fast and moderate-fast days. Conclusions: Days with high and fast intoxication are reflective of high-risk drinking behaviors and were most frequent among those at risk for alcohol use disorders. TAC research using MLPA may offer novel and important insights to intervention efforts.},
  publisher = {American Psychological Association (APA)},
}

@Article{Russell-Smyth-Turrisi-Rodriguez-2023,
  author = {Michael A. Russell and Joshua M. Smyth and Rob Turrisi and Gabriel C. Rodriguez},
  date = {2023-06},
  journaltitle = {Psychology of Addictive Behaviors},
  title = {Baseline protective behavioral strategy use predicts more moderate transdermal alcohol concentration dynamics and fewer negative consequences of drinking in young adults’ natural settings.},
  doi = {10.1037/adb0000941},
  issn = {0893-164X},
  number = {3},
  pages = {347--359},
  volume = {38},
  abstract = {Objective: Test whether frequent protective behavioral strategies (PBS) users report (a) fewer alcohol-related consequences and (b) less risky alcohol intoxication dynamics (measured via transdermal alcohol concentration [TAC] sensor ``features'') in daily life. Method: Two hundred twenty-two frequently heavy-drinking young adults ($M_{\mathrm{age}} = 22.3$ years) wore TAC sensors for 6 consecutive days. TAC features peak (maximum TAC), rise rate (speed of TAC increase), and area under the curve (AUC) were derived for each day. Negative alcohol-related consequences were measured in the morning after each self-reported drinking day. Past-year PBS use was measured at baseline. Results: Young adults reporting more frequent baseline PBS use showed (a) fewer alcohol-related consequences and (b) lower intoxication dynamics on average (less AUC, lower peaks, and slower rise rates). Limiting/stopping and manner of drinking PBS showed the same pattern of findings as the total score. Serious harm reduction PBS predicted fewer negative alcohol-related consequences, but not TAC features. Multilevel path models showed that TAC features peak and rise rate partially explained associations between PBS (total, limiting/stopping, and manner of drinking) and consequences. Independent contributions of PBS subscales were small and nonsignificant, suggesting that total PBS use was a more important predictor of risk/protection than the specific types of PBS used. Conclusions: Young adults using more total PBS may experience fewer alcohol-related consequences during real-world drinking episodes in part through less risky intoxication dynamics (TAC features). Future research measuring PBS at the daily level is needed to formally test TAC features as day-level mechanisms of protection from acute alcohol-related consequences.},
  publisher = {American Psychological Association (APA)},
}

@Article{Russell-Turrisi-Smyth-2022,
  author = {Michael A. Russell and Robert J. Turrisi and Joshua M. Smyth},
  date = {2022-01},
  journaltitle = {Alcoholism: Clinical and Experimental Research},
  title = {Transdermal sensor features correlate with ecological momentary assessment drinking reports and predict alcohol‐related consequences in young adults’ natural settings},
  doi = {10.1111/acer.14739},
  issn = {1530-0277},
  number = {1},
  pages = {100--113},
  volume = {46},
  abstract = {Background: Wearable transdermal alcohol concentration (TAC) sensors allow passive monitoring of alcohol concentration in natural settings and measurement of multiple features from drinking episodes, including peak intoxication level, speed of intoxication (absorption rate) and elimination, and duration. These passively collected features extend commonly used self-reported drink counts and may facilitate the prediction of alcohol-related consequences in natural settings, aiding risk stratification and prevention efforts. Method: A total of 222 young adults aged 21-29 ($M_{\mathrm{age}} = 22.3$, 64 female, 79\% non-Hispanic white, 84\% undergraduates) who regularly drink heavily participated in a 5-day study that included the ecological momentary assessment (EMA) of alcohol consumption (daily morning reports and participant-initiated episodic EMA sequences) and the wearing of TAC sensors (SCRAM-CAM anklets). The analytic sample contained 218 participants and 1274 days (including 554 self-reported drinking days). Five features—area under the curve (AUC), peak TAC, rise rate (rate of absorption), fall rate (rate of elimination), and duration—were extracted from TAC-positive trajectories for each drinking day. Day- and person-level associations of TAC features with drink counts (morning and episodic EMA) and alcohol-related consequences were tested using multilevel modeling. Results: TAC features were strongly associated with morning drink reports ($r$ = 0.60.7) but only moderately associated with episodic EMA drink counts ($r$ = 0.30.5) at both day and person levels. Higher peaks, larger AUCs, faster rise rates, and faster fall rates were significantly predictive of day-level alcohol-related consequences after adjusting for both morning and episodic EMA drink counts in separate models. Person means of TAC features added little above daily scores to the prediction of alcohol-related consequences. Conclusions: These results support the utility of TAC sensors in studies of alcohol misuse among young adults in natural settings and outline the specific TAC features that contribute to the day-level prediction of alcohol-related consequences. TAC sensors provide a passive option for obtaining valid and unique information predictive of drinking risk in natural settings.
},
  publisher = {Wiley},
}

@Article{Ryan-Hamaker-2021,
  author = {Oisin Ryan and Ellen L. Hamaker},
  date = {2021-06},
  journaltitle = {Psychometrika},
  title = {Time to intervene: A continuous-time approach to network analysis and centrality},
  doi = {10.1007/s11336-021-09767-0},
  number = {1},
  pages = {214--252},
  volume = {87},
  abstract = {Network analysis of ESM data has become popular in clinical psychology. In this approach, discrete-time (DT) vector auto-regressive (VAR) models define the network structure with centrality measures used to identify intervention targets. However, VAR models suffer from time-interval dependency. Continuous-time (CT) models have been suggested as an alternative but require a conceptual shift, implying that DT-VAR parameters reflect total rather than direct effects. In this paper, we propose and illustrate a CT network approach using CT-VAR models. We define a new network representation and develop centrality measures which inform intervention targeting. This methodology is illustrated with an ESM dataset.},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Savalei-Rosseel-2021,
  author = {Victoria Savalei and Yves Rosseel},
  date = {2021-10},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {Computational options for standard errors and test statistics with incomplete normal and nonnormal data in {SEM}},
  doi = {10.1080/10705511.2021.1877548},
  number = {2},
  pages = {163--181},
  volume = {29},
  abstract = {This article provides an overview of different computational options for inference following normal theory maximum likelihood (ML) estimation in structural equation modeling (SEM) with incomplete normal and nonnormal data. Complete data are covered as a special case. These computational options include whether the information matrix is observed or expected, whether the observed information matrix is estimated numerically or using an analytic asymptotic approximation, and whether the information matrix and the outer product matrix of the score vector are evaluated at the saturated or at the structured estimates. A variety of different standard errors and robust test statistics become possible by varying these options. We review the asymptotic properties of these computational variations, and we show how to obtain them using lavaan in R. We hope that this article will encourage methodologists to study the impact of the available computational options on the performance of standard errors and test statistics in SEM.},
  publisher = {Informa {UK} Limited},
  keywords = {incomplete data, nonnormal data, robust corrections, software implementation},
}

@Article{Shaygan-Karami-2020,
  author = {Maryam Shaygan and Zainab Karami},
  date = {2020},
  journaltitle = {International Journal of Community Based Nursing \& Midwifery},
  title = {Chronic pain in adolescents: Predicting role of emotional intelligence, self-esteem and parenting style},
  doi = {10.30476/ijcbnm.2020.83153.1129},
  volume = {8},
  abstract = {Background: Pediatric chronic pain is prevalent and disabling. The present study aimed to assess the prevalence of chronic pain among adolescents in Shiraz, Iran. We also compared emotional intelligence, self-esteem and parenting style between adolescents with chronic pain and healthy adolescents. Finally, we examined the predicting role of these variables regarding chronic pain in adolescents. Methods: This cross-sectional study, from January to June 2018, was conducted on 734 adolescents in Shiraz. A clustering sampling method was used. Adolescents with chronic pain were identified by affirmative answers to screening questions based on the International Classification of Diseases 11th Revision (ICD-11) criteria. Participants completed three validated self-report questionnaires: Trait Emotional Intelligence Questionnaire, Rosenberg self-esteem scale and Baumrind parenting style questionnaire. The data were analyzed through SPSS v.22 software using Mann-Whitney and binary logistic regression tests. P<0.05 was considered significant. Results: There were 221(30.1\%) adolescents who met the ICD-11 criteria of chronic pain. Mann-Whitney tests showed that emotional intelligence (P<0.001), self-esteem (P<0.001), authoritative parenting style (P=0.004), and authoritarian parenting style (P=0.006) were significantly different in adolescents with chronic pain compared to healthy adolescents. Binary logistic regression revealed that emotional intelligence (P<0.001), self-esteem (P<0.001), authoritarian parenting style (P=0.04) and authoritative parenting style (P=0.01) were significantly correlated with chronic pain after controlling for demographic variables. Conclusion: Our findings indicate that emotional intelligence, self-esteem and parenting styles could be important factors in development or maintenance of chronic pain in adolescents. The results have potential to be extended to future interventions for adolescents with chronic pain.},
  publisher = {Shiraz University of Medical Sciences, Shiraz, Iran},
}

@Article{Tofighi-Kelley-2020,
  author = {Davood Tofighi and Ken Kelley},
  date = {2020},
  journaltitle = {Psychological Methods},
  title = {Improved inference in mediation analysis: Introducing the model-based constrained optimization procedure},
  doi = {10.1037/met0000259},
  pages = {496--515},
  volume = {25},
  abstract = {Mediation analysis is an important approach for investigating causal pathways. One approach used in mediation analysis is the test of an indirect effect, which seeks to measure how the effect of an independent variable impacts an outcome variable through one or more mediators. However, in many situations the proposed tests of indirect effects, including popular confidence interval-based methods, tend to produce poor Type I error rates when mediation does not occur and, more generally, only allow dichotomous decisions of ``not significant'' or ``significant'' with regards to the statistical conclusion. To remedy these issues, we propose a new method, a likelihood ratio test (LRT), that uses non-linear constraints in what we term the model-based constrained optimization (MBCO) procedure. The MBCO procedure (a) offers a more robust Type I error rate than existing methods; (b) provides a p-value, which serves as a continuous measure of compatibility of data with the hypothesized null model (not just a dichotomous reject or fail-to-reject decision rule); (c) allows simple and complex hypotheses about mediation (i.e., one or more mediators; different mediational pathways), and (d) allows the mediation model to use observed or latent variables. The MBCO procedure is based on a structural equation modeling framework (even if latent variables are not specified) with specialized fitting routines, namely with the use of non-linear constraints. We advocate using the MBCO procedure to test hypotheses about an indirect effect in addition to reporting a confidence interval to capture uncertainty about the indirect effect because this combination transcends existing methods.},
  publisher = {{American Psychological Association ({APA})}},
}

@Article{Usami-2020,
  author = {Satoshi Usami},
  date = {2020-10},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  title = {On the differences between general cross-lagged panel model and random-intercept cross-lagged panel model: Interpretation of cross-lagged parameters and model choice},
  doi = {10.1080/10705511.2020.1821690},
  issn = {1532-8007},
  number = {3},
  pages = {331--344},
  volume = {28},
  abstract = {Many methods have been developed to infer reciprocal relations between longitudinally observed variables. Among them, the general cross-lagged panel model (GCLM) is the most recent development as a variant of the cross-lagged panel model (CLPM), while the random-intercept CLPM (RI-CLPM) has rapidly become a popular approach. In this article, we describe how common factors and cross-lagged parameters included in these models can be interpreted, using a unified framework that was recently developed. Because common factors are modeled with lagged effects in the GCLM, they have both direct and indirect influences on observed scores, unlike stable trait factors included in the RI-CLPM. This indicates that the GCLM does not control for stable traits as the RI-CLPM does, and that there are interpretative differences in cross-lagged parameters between these models. We also explain that including such common factors as well as moving-average terms in the GCLM makes this interpretation very complicated.},
  publisher = {Informa UK Limited},
}

@Article{Usami-2022,
  author = {Satoshi Usami},
  date = {2022-08},
  journaltitle = {Psychometrika},
  title = {Within-person variability score-based causal inference: A two-step estimation for joint effects of time-varying treatments},
  doi = {10.1007/s11336-022-09879-1},
  issn = {1860-0980},
  number = {4},
  pages = {1466--1494},
  volume = {88},
  abstract = {Behavioral science researchers have shown strong interest in disaggregating within-person relations from between-person differences (stable traits) using longitudinal data. In this paper, we propose a method of within-person variability score-based causal inference for estimating joint effects of time-varying continuous treatments by controlling for stable traits of persons. After explaining the assumed data-generating process and providing formal definitions of stable trait factors, within-person variability scores, and joint effects of time-varying treatments at the within-person level, we introduce the proposed method, which consists of a two-step analysis. Within-person variability scores for each person, which are disaggregated from stable traits of that person, are first calculated using weights based on a best linear correlation preserving predictor through structural equation modeling (SEM). Causal parameters are then estimated via a potential outcome approach, either marginal structural models (MSMs) or structural nested mean models (SNMMs), using calculated within-person variability scores. Unlike the approach that relies entirely on SEM, the present method does not assume linearity for observed time-varying confounders at the within-person level. We emphasize the use of SNMMs with G-estimation because of its property of being doubly robust to model misspecifications in how observed time-varying confounders are functionally related to treatments/predictors and outcomes at the within-person level. Through simulation, we show that the proposed method can recover causal parameters well and that causal estimates might be severely biased if one does not properly account for stable traits. An empirical application using data regarding sleep habits and mental health status from the Tokyo Teen Cohort study is also provided.},
  publisher = {Springer Science and Business Media LLC},
}

@Article{vanEgmond-Wright-Livingston-etal-2020,
  author = {Kelly {van Egmond} and Cassandra J. C. Wright and Michael Livingston and Emmanuel Kuntsche},
  date = {2020-10},
  journaltitle = {Alcoholism: Clinical and Experimental Research},
  title = {Wearable transdermal alcohol monitors: A systematic review of detection validity, and relationship between transdermal and breath alcohol concentration and influencing factors},
  doi = {10.1111/acer.14432},
  issn = {1530-0277},
  number = {10},
  pages = {1918--1932},
  volume = {44},
  abstract = {Background Research on alcohol consumption mostly relies on self-reported data, which are subject to recall bias. Wearable transdermal alcohol concentration (TAC) monitors address this limitation by continuously measuring the ethanol excreted via the skin. This systematic review aims to provide an overview of TAC monitors' reliability to detect alcohol consumption and methods to estimate breath alcohol concentration (BrAC) and number of standard drinks consumed in a given time frame. Methods The databases MEDLINE, PsycINFO, SCOPUS, Engineering Village, and CINAHL were systematically searched to identify 1,048 empirical research papers published from 2013 onwards, of which 13 were included after full-text screening. The selected studies included 3 TAC monitors: SCRAM, WristTAS, and Skyn. Results TAC measures of SCRAM, WrisTAS, and Skyn are found to be positively correlated with BrAC ($r = 0.56$ to $0.79$) and/or self-reports ($r = 0.62$). Using the AMS criteria for detection results in low sensitivity, adjusted criteria can increase the sensitivity of the SCRAM from $39.9$ to $68.5\%$. The WrisTAS and an early prototype of the Skyn showed high failure rates ($17$ to $38\%$). Recent advances toward transforming the TAC data into more clinically relevant measures have led to the development of mathematical models and the BrAC Estimator Software. Using TAC data, both approaches produce estimates explaining $70$ to $82\%$ of actual BrAC and self-reported drinking or to highly correlate with the actual BrAC measures ($\beta = 0.90$ to $0.91$). Conclusions Transdermal alcohol monitors offer an opportunity to measure alcohol consumption in a valid and continuous way with mathematical models and software estimating BrAC values improving interpretation of TAC data. However, the SCRAM seems unable to detect low-to-moderate drinking levels using the thresholds and criteria set by the manufacturer. Moreover, the WrisTAS and the Skyn prototype show a high failure rate, raising questions about reliability. Future studies will assess the validity of new-generation wristbands, including the next Skyn generations.},
  publisher = {Wiley},
}

@Article{Wang-Zhang-2020,
  author = {Lijuan Wang and Qian Zhang},
  date = {2020-06},
  journaltitle = {Psychological Methods},
  title = {Investigating the impact of the time interval selection on autoregressive mediation modeling: Result interpretations, effect reporting, and temporal designs},
  doi = {10.1037/met0000235},
  number = {3},
  pages = {271--291},
  volume = {25},
  abstract = {This study investigates the impact of the time interval (the time passed between 2 consecutive measurements) selection on autoregressive mediation modeling (AMM). For a widely used autoregressive mediation model, via analytical derivations, we explained why and how the conventionally reported time-specific coefficient estimates (e.g., $\hat{a} \hat{b}$ and $\hat{c}^{\prime}$ ) and inference results in AMM provide limited information and can arrive in even misleading conclusions about direct and indirect effects over time. Furthermore, under the stationarity assumption, we proposed an approach to calculate the overall direct and indirect effect estimates over time and the time lag lengths at which they reach maxima, using AMM results. The derivation results revealed that the overall direct and indirect effect curves are asymptotically invariant to the time interval selection, under stationarity. With finite samples and thus sampling errors and potential computing problems, however, our simulation results revealed that the overall indirect effect curves were better recovered when the time interval is selected to be closer to half of the time lag length at which the overall indirect effect reaches its maximum. An R function and an R Shiny app were developed to obtain the overall direct and indirect effect curves over time and facilitate the time interval selection using AMM results. Our findings provide another look at the connections between AMM and continuous time mediation modeling and the connections are discussed.},
  publisher = {American Psychological Association ({APA})},
  keywords = {longitudinal mediation, autoregressive mediation modeling, time interval selection, time-specific indirect effect, overall indirect effect},
  annotation = {ild, ild-mediation},
}

@Article{Zeileis-Koll-Graham-2020,
  author = {Achim Zeileis and Susanne K{\"o}ll and Nathaniel Graham},
  date = {2020-10},
  journaltitle = {Journal of Statistical Software},
  title = {Various versatile variances: An object-oriented implementation of clustered covariances in {R}},
  doi = {10.18637/jss.v095.i01},
  number = {1},
  volume = {95},
  abstract = {Clustered covariances or clustered standard errors are very widely used to account for correlated or clustered data, especially in economics, political sciences, and other social sciences. They are employed to adjust the inference following estimation of a standard least-squares regression or generalized linear model estimated by maximum likelihood. Although many publications just refer to "the" clustered standard errors, there is a surprisingly wide variety of clustered covariances, particularly due to different flavors of bias corrections. Furthermore, while the linear regression model is certainly the most important application case, the same strategies can be employed in more general models (e.g., for zero-inflated, censored, or limited responses). In R, functions for covariances in clustered or panel models have been somewhat scattered or available only for certain modeling functions, notably the (generalized) linear regression model. In contrast, an object-oriented approach to ``robust''' covariance matrix estimation - applicable beyond lm() and glm() - is available in the sandwich package but has been limited to the case of cross-section or time series data. Starting with sandwich 2.4.0, this shortcoming has been corrected: Based on methods for two generic functions (estfun() and bread()), clustered and panel covariances are provided in vcovCL(), vcovPL(), and vcovPC(). Moreover, clustered bootstrap covariances are provided in vcovBS(), using model update() on bootstrap samples. These are directly applicable to models from packages including MASS, pscl, countreg, and betareg, among many others. Some empirical illustrations are provided as well as an assessment of the methods' performance in a simulation study.},
  publisher = {Foundation for Open Access Statistic},
}
